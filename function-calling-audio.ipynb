{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "String userHomeDir = System.getProperty(\"user.home\");\n",
    "String localRespoUrl = \"file://\" + userHomeDir + \"/.m2/repository/\";\n",
    "String langchain4jVersion = \"0.36.0-SNAPSHOT\";\n",
    "String dotenvJavaVersion = \"3.0.2\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm -rf \\{userHomeDir}/Library/Jupyter/kernels/rapaio-jupyter-kernel/mima_cache/dev/ai4j/openai4j\n",
    "rm -rf \\{userHomeDir}/Library/Jupyter/kernels/rapaio-jupyter-kernel/mima_cache/dev/langchain4j/langchain4j-open-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dependency /add-repo local \\{localRespoUrl} release|never snapshot|always\n",
    "%dependency /list-repos\n",
    "%dependency /add dev.ai4j:openai4j:0.23.0-CUSTOM\n",
    "%dependency /add dev.langchain4j:langchain4j-open-ai:0.36.0-CUSTOM // Custom Audio\n",
    "%dependency /resolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dependency /add dev.langchain4j:langchain4j:\\{langchain4jVersion}\n",
    "%dependency /add io.github.cdimascio:dotenv-java:\\{dotenvJavaVersion}\n",
    "%dependency /add org.slf4j:slf4j-jdk14:2.0.9\n",
    "%dependency /add ch.qos.logback:logback-classic:1.5.8\n",
    "%dependency /list-dependencies\n",
    "%dependency /resolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io.github.cdimascio.dotenv.Dotenv;\n",
    "Dotenv dotenv = Dotenv.load();\n",
    "String API_KEY = dotenv.get(\"OPENAI_API_KEY\");\n",
    "String OPENAI_API_KEY = API_KEY;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.model.chat.listener.ChatModelListener;\n",
    "import dev.langchain4j.model.chat.listener.ChatModelResponseContext;\n",
    "import dev.langchain4j.model.chat.listener.ChatModelResponse;\n",
    "import dev.langchain4j.model.chat.listener.ChatModelRequest;\n",
    "import dev.langchain4j.data.message.UserMessage;\n",
    "\n",
    "import dev.ai4j.openai4j.OpenAiClient;\n",
    "import dev.ai4j.openai4j.chat.ChatCompletionRequest;\n",
    "import dev.ai4j.openai4j.chat.ChatCompletionResponse;\n",
    "import dev.ai4j.openai4j.chat.AssistantMessage;\n",
    "\n",
    "\n",
    "import javax.sound.sampled.*;\n",
    "import java.io.ByteArrayInputStream;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.IOException;\n",
    "import java.util.Arrays;\n",
    "import java.util.Base64;\n",
    "import static java.util.Arrays.asList;\n",
    "\n",
    "// Custom Code\n",
    "import dev.ai4j.openai4j.chat.AudioSettings;\n",
    "\n",
    "import dev.langchain4j.agent.tool.Tool;\n",
    "import dev.langchain4j.service.AiServices;\n",
    "import dev.langchain4j.service.UserMessage;\n",
    "import dev.langchain4j.service.SystemMessage;\n",
    "import dev.langchain4j.model.chat.request.ResponseFormatType;\n",
    "\n",
    "import java.time.ZoneId;\n",
    "import java.time.LocalDateTime;\n",
    "import java.time.format.DateTimeFormatter;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ./hello-world.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface TimeKeeper {\n",
    "    @SystemMessage(\"指定したタイムゾーンの現在の時刻を何時何分の形式で答えてください\")\n",
    "    String ask(String question);\n",
    "}\n",
    "\n",
    "class Clock {\n",
    "    @Tool\n",
    "    public LocalDateTime getCurrentTimeInTimeZone(String timeZoneId) {\n",
    "        System.out.println(\"タイムゾーン: \" + timeZoneId);\n",
    "        return LocalDateTime.now(ZoneId.of(timeZoneId));\n",
    "    }\n",
    "}\n",
    "\n",
    "TimeKeeper timeKeeper = AiServices.builder(TimeKeeper.class)\n",
    "    .chatLanguageModel(model)\n",
    "    .tools(new Clock())\n",
    "    .build();\n",
    "\n",
    "String now = timeKeeper.ask(\"日本の時間で今何時？\");\n",
    "System.out.println(now);  // 例: \"現在の時刻は16:58です\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "// AssistantMessage.AudioData を格納するコンテナオブジェクト\n",
    "class AudioDataContainer {\n",
    "    private AssistantMessage.AudioData audioData;\n",
    "    public AssistantMessage.AudioData getAudioData() {\n",
    "        return audioData;\n",
    "    }\n",
    "    public void setAudioData(AssistantMessage.AudioData audioData) {\n",
    "        this.audioData = audioData;\n",
    "    }\n",
    "}\n",
    "final AudioDataContainer audioDataContainer = new AudioDataContainer();\n",
    "\n",
    "ChatModelListener listener = new ChatModelListener() {\n",
    "    @Override\n",
    "    public void onResponse(ChatModelResponseContext responseContext) {\n",
    "        try {\n",
    "            ChatModelResponse response = responseContext.response();\n",
    "            ChatModelRequest request = responseContext.request();\n",
    "            Map<Object, Object> attributes = responseContext.attributes();        \n",
    "            AssistantMessage.AudioData audioData = (AssistantMessage.AudioData) attributes.get(\"audio\");\n",
    "            if (audioData == null) {\n",
    "                System.out.println(\"No audio data found in the response\");\n",
    "                return;\n",
    "            }\n",
    "            audioDataContainer.setAudioData(audioData);\n",
    "            /*\n",
    "            String data = audioData.data();\n",
    "            System.out.println(\"data: \" + data);\n",
    "            byte[] audioBytes = Base64.getDecoder().decode(data);\n",
    "            playAudio(audioBytes);    \n",
    "            System.out.println(\"transcript: \" + audioData.transcript());\n",
    "            */\n",
    "        } catch (Exception e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.model.chat.ChatLanguageModel;\n",
    "import dev.langchain4j.model.openai.OpenAiChatModel;\n",
    "import dev.langchain4j.data.message.AiMessage;\n",
    "import dev.langchain4j.model.output.Response;\n",
    "\n",
    "import static dev.langchain4j.model.openai.OpenAiChatModelName.GPT_4_O_MINI;\n",
    "\n",
    "var audioSettings = new AudioSettings(\"nova\", \"wav\"); // Custom Code\n",
    "var modalities = asList(\"text\", \"audio\"); // Custom Code\n",
    "\n",
    "ChatLanguageModel audioModel = OpenAiChatModel.builder()\n",
    "    .apiKey(API_KEY)\n",
    "    .logRequests(true)\n",
    "    .logResponses(true) \n",
    "    //.modelName(\"gpt-4o-mini\")\n",
    "    .modelName(\"gpt-4o-audio-preview\")\n",
    "    .audioSettings(audioSettings) // Custom Code\n",
    "    .modalities(modalities)  // Custom Code\n",
    "    .listeners(List.of(listener)) // Custom Code\n",
    "    .build();\n",
    "\n",
    "interface Assistant {  \n",
    "    @UserMessage(\"\"\"\n",
    "    あなたはLangChain4jによって作られたエージェントです。\n",
    "    今JJUG(ジェイジャグ)の会場にいます。LangChain4jのセッションをします。\n",
    "    会場にいる人に自己紹介と現在時刻を伝えてください。\n",
    "    あなたが時刻を知っていることは珍しいので、そのことも伝えてください。\n",
    "    最後に短くご挨拶をしてください。\n",
    "    {{it}}\n",
    "    \"\"\")\n",
    "    String greeting(String nowString);\n",
    "}\n",
    "\n",
    "Assistant assistant = AiServices.builder(Assistant.class)\n",
    "    .chatLanguageModel(audioModel)\n",
    "    .build();\n",
    "String response = assistant.greeting(now);\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssistantMessage.AudioData audioData = audioDataContainer.getAudioData();\n",
    "if (audioData == null) {\n",
    "    System.out.println(\"No audio data found in the response\");    \n",
    "} else {\n",
    "    System.out.println(\"transcript: \" + audioData);\n",
    "    String data = audioData.data();\n",
    "    // System.out.println(\"data: \" + data);\n",
    "    byte[] audioBytes = Base64.getDecoder().decode(data);          \n",
    "    var bais = new ByteArrayInputStream(audioBytes);\n",
    "    var audioInputStream = AudioSystem.getAudioInputStream(bais);\n",
    "    Clip clip = AudioSystem.getClip();\n",
    "    clip.open(audioInputStream);\n",
    "    clip.start();\n",
    "    while (clip.isRunning()) {\n",
    "        Thread.sleep(100);\n",
    "    }\n",
    "    clip.close();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.ByteArrayInputStream;\n",
    "import java.io.File;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.IOException;\n",
    "import java.util.Base64;\n",
    "\n",
    "import javax.sound.sampled.AudioInputStream;\n",
    "import javax.sound.sampled.AudioSystem;\n",
    "\n",
    "\n",
    "AssistantMessage.AudioData audioData = audioDataContainer.getAudioData();\n",
    "if (audioData == null) {\n",
    "    System.out.println(\"No audio data found in the response\");\n",
    "} else {\n",
    "    System.out.println(\"transcript: \" + audioData);\n",
    "    String data = audioData.data();\n",
    "    byte[] audioBytes = Base64.getDecoder().decode(data);\n",
    "\n",
    "    // 一時ファイルに書き出す\n",
    "    File tempWavFile = File.createTempFile(\"temp_audio\", \".wav\");\n",
    "    try (FileOutputStream fos = new FileOutputStream(tempWavFile)) {\n",
    "        fos.write(audioBytes);\n",
    "    }\n",
    "\n",
    "    // コマンドラインで実行する\n",
    "    String os = System.getProperty(\"os.name\").toLowerCase();\n",
    "    ProcessBuilder processBuilder;\n",
    "\n",
    "    if (os.contains(\"mac\")) {\n",
    "        processBuilder = new ProcessBuilder(\"afplay\", tempWavFile.getAbsolutePath());\n",
    "    } else if (os.contains(\"win\")) {\n",
    "        processBuilder = new ProcessBuilder(\"cmd\", \"/c\", \"start\", \"wmplayer\", tempWavFile.getAbsolutePath());\n",
    "    } else {\n",
    "        throw new UnsupportedOperationException(\"Unsupported OS: \" + os);\n",
    "    }\n",
    "\n",
    "    Process process = processBuilder.start();\n",
    "    process.waitFor(); // 再生が終了するまで待機\n",
    "\n",
    "    // 再生終了後に一時ファイルを削除\n",
    "    tempWavFile.deleteOnExit();\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java (rjk 2.1.0)",
   "language": "java",
   "name": "rapaio-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "java",
   "nbconvert_exporter": "script",
   "pygments_lexer": "java",
   "version": "22.0.2+9-jvmci-b01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
